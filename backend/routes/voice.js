const express = require('express');
const router = express.Router();
const multer = require('multer');
const path = require('path');

// Configure multer for audio uploads
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, 'uploads/audio/');
  },
  filename: (req, file, cb) => {
    cb(null, Date.now() + '-' + Math.round(Math.random() * 1E9) + path.extname(file.originalname));
  }
});

const upload = multer({ 
  storage: storage,
  fileFilter: (req, file, cb) => {
    const allowedTypes = /wav|mp3|webm|ogg|m4a/;
    const extname = allowedTypes.test(path.extname(file.originalname).toLowerCase());
    const mimetype = allowedTypes.test(file.mimetype);
    
    if (mimetype && extname) {
      return cb(null, true);
    } else {
      cb(new Error('Only audio files are allowed'));
    }
  },
  limits: { fileSize: 10 * 1024 * 1024 } // 10MB limit
});

// Twilio Voice webhook for incoming calls
router.post('/incoming-call', (req, res) => {
  const { From, To } = req.body;
  
  console.log(`üìû Incoming call from ${From} to ${To}`);
  
  // TwiML response for voice call
  res.set('Content-Type', 'text/xml');
  res.send(`<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Gather input="speech" action="/api/voice/process-speech" method="POST" speechTimeout="3" language="hi-IN">
    <Say voice="Polly.Aditi" language="hi-IN">
      ‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ AI ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™‡§ï‡•Ä ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§è‡§Ç‡•§
    </Say>
  </Gather>
  <Say voice="Polly.Aditi" language="hi-IN">
    ‡§Ü‡§™‡§æ‡§§‡§ï‡§æ‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è 108 ‡§°‡§æ‡§Ø‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§
  </Say>
</Response>`);
});

// Process speech input from Twilio
router.post('/process-speech', async (req, res) => {
  try {
    const { SpeechResult, From } = req.body;
    
    console.log(`üé§ Speech from ${From}: "${SpeechResult}"`);
    
    if (!SpeechResult) {
      res.set('Content-Type', 'text/xml');
      return res.send(`<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Say voice="Polly.Aditi" language="hi-IN">
    ‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§∏‡§Æ‡§ù ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§ï‡§π‡•á‡§Ç‡•§
  </Say>
  <Hangup/>
</Response>`);
    }
    
    // Get AI response (reuse existing chat logic)
    const aiResponse = await getChatResponse(SpeechResult, From, 'hi');
    
    // Convert AI response to speech-friendly format
    const speechText = aiResponse.response
      .replace(/\*\*(.*?)\*\*/g, '$1') // Remove bold formatting
      .replace(/‚Ä¢/g, '') // Remove bullet points
      .replace(/\n/g, '. ') // Replace newlines with pauses
      .substring(0, 500); // Limit length for voice
    
    res.set('Content-Type', 'text/xml');
    res.send(`<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Say voice="Polly.Aditi" language="hi-IN">
    ${speechText}
  </Say>
  <Pause length="2"/>
  <Say voice="Polly.Aditi" language="hi-IN">
    ‡§Ü‡§™‡§æ‡§§‡§ï‡§æ‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è 108 ‡§°‡§æ‡§Ø‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§∏‡•ç‡§µ‡§∏‡•ç‡§• ‡§∞‡§π‡•á‡§Ç‡•§
  </Say>
  <Hangup/>
</Response>`);
    
  } catch (error) {
    console.error('Voice processing error:', error);
    res.set('Content-Type', 'text/xml');
    res.send(`<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Say voice="Polly.Aditi" language="hi-IN">
    ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ü‡§™‡§æ‡§§‡§ï‡§æ‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è 108 ‡§°‡§æ‡§Ø‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§
  </Say>
  <Hangup/>
</Response>`);
  }
});

// Upload audio file for processing
router.post('/upload-audio', upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No audio file uploaded' });
    }
    
    const audioPath = req.file.path;
    console.log(`üéµ Audio uploaded: ${audioPath}`);
    
    // Here you would integrate with speech-to-text service
    // For now, return a placeholder response
    res.json({
      success: true,
      message: 'Audio uploaded successfully',
      transcript: 'Audio processing not implemented yet',
      audioPath: audioPath
    });
    
  } catch (error) {
    console.error('Audio upload error:', error);
    res.status(500).json({ error: 'Audio upload failed' });
  }
});

// Get chat response (reuse from chat.js)
async function getChatResponse(message, userId, language) {
  try {
    const axios = require('axios');
    const response = await axios.post('http://localhost:9000/api/chat', {
      message, userId, language
    });
    return response.data;
  } catch (error) {
    return {
      response: '‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ü‡§™‡§æ‡§§‡§ï‡§æ‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è 108 ‡§°‡§æ‡§Ø‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§',
      confidence: 0.5
    };
  }
}

// Test voice endpoint
router.get('/test', (req, res) => {
  res.json({
    message: 'Voice API is working!',
    features: [
      'Twilio Voice Calls',
      'Speech Recognition',
      'Text-to-Speech',
      'Audio File Upload'
    ]
  });
});

module.exports = router;